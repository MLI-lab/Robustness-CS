{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/root/bart-0.5.00/python/')\n",
    "\n",
    "\n",
    "import logging\n",
    "import multiprocessing\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import bart\n",
    "from common import utils\n",
    "from common.args import Args\n",
    "from common.subsample import create_mask_for_mask_type\n",
    "from common.utils import tensor_to_complex_np\n",
    "from data import transforms\n",
    "from data.mri_data import SliceData\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer that masks input k-space.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mask_func (common.subsample.MaskFunc): A function that can create a mask of\n",
    "                appropriate shape.\n",
    "        \"\"\"\n",
    "        self.mask_func = mask_func\n",
    "\n",
    "    def __call__(self, kspace, target, attrs, fname, slice):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            kspace (numpy.array): Input k-space of shape (num_coils, rows, cols, 2) for multi-coil\n",
    "                data or (rows, cols, 2) for single coil data.\n",
    "            target (numpy.array, optional): Target image\n",
    "            attrs (dict): Acquisition related information stored in the HDF5 object.\n",
    "            fname (str): File name\n",
    "            slice (int): Serial number of the slice.\n",
    "        Returns:\n",
    "            (tuple): tuple containing:\n",
    "                masked_kspace (torch.Tensor): Sub-sampled k-space with the same shape as kspace.\n",
    "                fname (str): File name containing the current data item\n",
    "                slice (int): The index of the current slice in the volume\n",
    "        \"\"\"\n",
    "        kspace = transforms.to_tensor(kspace)\n",
    "        seed = tuple(map(ord, fname))\n",
    "        # Apply mask to raw k-space\n",
    "        masked_kspace, mask = transforms.apply_mask(kspace, self.mask_func, seed)\n",
    "        return masked_kspace, fname, slice\n",
    "\n",
    "\n",
    "def create_data_loader(args):\n",
    "    dev_mask = create_mask_for_mask_type(args.mask_type, args.center_fractions, args.accelerations)\n",
    "    data = SliceData(\n",
    "        root=args.data_path + str(f'{args.challenge}_val'),\n",
    "        transform=DataTransform(dev_mask),\n",
    "        challenge=args.challenge,\n",
    "        sample_rate=args.sample_rate\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def cs_total_variation(args, kspace):\n",
    "    \"\"\"\n",
    "    Run ESPIRIT coil sensitivity estimation and Total Variation Minimization based\n",
    "    reconstruction algorithm using the BART toolkit.\n",
    "    \"\"\"\n",
    "\n",
    "    if args.challenge == 'singlecoil':\n",
    "        kspace = kspace.unsqueeze(0)\n",
    "    kspace = kspace.permute(1, 2, 0, 3).unsqueeze(0)\n",
    "    kspace = tensor_to_complex_np(kspace)\n",
    "\n",
    "    # Estimate sensitivity maps\n",
    "    sens_maps = bart.bart(1, f'ecalib -d0 -m1', kspace)\n",
    "\n",
    "    # Use Total Variation Minimization to reconstruct the image\n",
    "    pred = bart.bart(\n",
    "        1, f'pics -d0 -S -R T:7:0:{args.reg_wt} -i {args.num_iters}', kspace, sens_maps\n",
    "    )\n",
    "    pred = torch.from_numpy(np.abs(pred[0]))\n",
    "\n",
    "    # Crop the predicted image to selected resolution if bigger\n",
    "    smallest_width = min(args.resolution, pred.shape[-1])\n",
    "    smallest_height = min(args.resolution, pred.shape[-2])\n",
    "    return transforms.center_crop(pred, (smallest_height, smallest_width))\n",
    "\n",
    "\n",
    "def run_model(i):\n",
    "    masked_kspace, fname, slice = data[i]\n",
    "    prediction = cs_total_variation(args, masked_kspace)\n",
    "    return fname, slice, prediction\n",
    "\n",
    "\n",
    "def main():\n",
    "    if args.num_procs == 0:\n",
    "        start_time = time.perf_counter()\n",
    "        outputs = []\n",
    "        for i in range(len(data)):\n",
    "            outputs.append(run_model(i))\n",
    "            save_outputs([run_model(i)], args.output_path)\n",
    "        time_taken = time.perf_counter() - start_time\n",
    "    else:\n",
    "        with multiprocessing.Pool(args.num_procs) as pool:\n",
    "            start_time = time.perf_counter()\n",
    "            outputs = pool.map(run_model, range(len(data)))\n",
    "            time_taken = time.perf_counter() - start_time\n",
    "            save_outputs(outputs, args.output_path)\n",
    "    logging.info(f'Run Time = {time_taken:}s')\n",
    "    \n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "def save_reconstructions(reconstructions, out_dir):\n",
    "    \"\"\"\n",
    "    Saves the reconstructions from a model into h5 files that is appropriate for submission\n",
    "    to the leaderboard.\n",
    "\n",
    "    Args:\n",
    "        reconstructions (dict[str, np.array]): A dictionary mapping input filenames to\n",
    "            corresponding reconstructions (of shape num_slices x height x width).\n",
    "        out_dir (pathlib.Path): Path to the output directory where the reconstructions\n",
    "            should be saved.\n",
    "    \"\"\"\n",
    "    for fname, recons in reconstructions.items():\n",
    "        with h5py.File(out_dir + fname, 'w') as f:\n",
    "            f.create_dataset('reconstruction', data=recons)\n",
    "            \n",
    "def save_outputs(outputs, output_path):\n",
    "    reconstructions = defaultdict(list)\n",
    "    for fname, slice, pred in outputs:\n",
    "        reconstructions[fname].append((slice, pred))\n",
    "    reconstructions = {\n",
    "        fname: np.stack([pred for _, pred in sorted(slice_preds)])\n",
    "        for fname, slice_preds in reconstructions.items()\n",
    "    }\n",
    "    save_reconstructions(reconstructions, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self,ch,path,rate,acc,cent,outpath,iters,reg,procs,maskt,seed,res):\n",
    "        self.challenge = ch\n",
    "        self.data_path = path\n",
    "        self.sample_rate = rate\n",
    "        self.accelerations = acc\n",
    "        self.center_fractions = cent\n",
    "        self.output_path = outpath\n",
    "        self.num_iters = iters\n",
    "        self.reg_wt = reg\n",
    "        self.num_procs = procs\n",
    "        self.mask_type = maskt\n",
    "        self.seed = seed\n",
    "        self.resolution = res\n",
    "args = Args(\"multicoil\",\"/hdd/\",1,[8],[0.035],\"/root/multires_deep_decoder/mri/FINAL/TV_8x/\",100,0.01,4,\"random\",42,320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "os.environ['TOOLBOX_PATH'] = \"/root/bart-0.5.00/\" # visible in this process + all children\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "dataset = create_data_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((PosixPath('/hdd/multicoil_val/file1000017.h5'), 7), 7135, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.examples[80],len(dataset),len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file1000000.h5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dataset.examples[0][0]).split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wofs = [\"file1000885\",\"file1000552\",\"file1001598\",\"file1000283\",\"file1001184\"]\n",
    "fs = [\"file1000007\",\"file1000480\",\"file1000591\",\"file1002380\",\"file1001090\",\"file1000990\",\"file1001144\",\"file1000528\"]\n",
    "F = wofs + fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file1000356',\n",
       " 'file1000759',\n",
       " 'file1000196',\n",
       " 'file1000932',\n",
       " 'file1002007',\n",
       " 'file1000817',\n",
       " 'file1000871',\n",
       " 'file1001793',\n",
       " 'file1001715',\n",
       " 'file1000052',\n",
       " 'file1001798',\n",
       " 'file1002155']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"../../8xfilenames\",\"rb\") as fn:\n",
    "    filenames = pickle.load(fn)\n",
    "F = [f.split('/')[-1].split('.')[0] for f in filenames]\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Run Time = 369.2502293130383s\n",
      "INFO:root:Run Time = 318.16306800208986s\n",
      "INFO:root:Run Time = 360.3594573449809s\n",
      "INFO:root:Run Time = 370.8382950189989s\n",
      "INFO:root:Run Time = 299.64554103580303s\n",
      "INFO:root:Run Time = 303.613717908971s\n",
      "INFO:root:Run Time = 261.25569913792424s\n",
      "INFO:root:Run Time = 283.72581244120374s\n",
      "INFO:root:Run Time = 336.82601965987124s\n",
      "INFO:root:Run Time = 307.7307924958877s\n",
      "INFO:root:Run Time = 241.05443193903193s\n"
     ]
    }
   ],
   "source": [
    "this_data = []\n",
    "prev_slicenu = -1\n",
    "for i,d in enumerate(dataset):\n",
    "    if str(dataset.examples[i][0]).split('/')[-1].split('.')[0] not in F:\n",
    "        continue\n",
    "    if dataset.examples[i][1] > prev_slicenu: \n",
    "        this_data.append(d)\n",
    "        prev_slicenu = dataset.examples[i][1]\n",
    "    else:\n",
    "        data = this_data\n",
    "        main()\n",
    "        this_data = [d]\n",
    "        prev_slicenu = 0\n",
    "    if i == len(dataset) - 1:\n",
    "        data = this_data\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
